// This is an autogenerated file from Firebase Studio.

'use server';

/**
 * @fileOverview Suggests laptops with similar specifications.
 *
 * - suggestLaptops - A function that suggests laptops based on a given set of specs.
 * - SuggestLaptopsInput - The input type for the suggestLaptops function.
 * - SuggestLaptopsOutput - The return type for the suggestLaptops function.
 */

import {ai} from '@/ai/genkit';
import {z} from 'genkit';
import { laptopData } from '@/lib/data';
import type { Product } from '@/lib/types';


const SuggestLaptopsInputSchema = z.object({
    cpu: z.string().describe('The CPU of the laptop to base suggestions on.'),
    gpu: z.string().describe('The GPU of the laptop to base suggestions on.'),
    ram: z.string().describe('The RAM of the laptop to base suggestions on.'),
});
export type SuggestLaptopsInput = z.infer<
  typeof SuggestLaptopsInputSchema
>;

const SuggestLaptopsOutputSchema = z.object({
    suggestions: z.array(z.object({
        id: z.string(),
        category: z.enum(['laptop', 'peripheral']),
        name: z.string(),
        price: z.number(),
        url: z.string(),
        imageUrl: z.string(),
        dataAiHint: z.string(),
        specs: z.array(z.object({
            name: z.string(),
            value: z.string(),
            icon: z.string(),
        })),
    })).describe('A list of suggested laptops.'),
});

export type SuggestLaptopsOutput = z.infer<
  typeof SuggestLaptopsOutputSchema
>;

export async function suggestLaptops(
  input: SuggestLaptopsInput
): Promise<SuggestLaptopsOutput> {
  return suggestLaptopsFlow(input);
}

const prompt = ai.definePrompt({
    name: 'laptopSuggestionPrompt',
    input: { schema: SuggestLaptopsInputSchema },
    output: { schema: SuggestLaptopsOutputSchema },
    prompt: `You are a laptop recommendation expert. Based on the following specifications, suggest 3 other laptops from the provided list that have similar or better specs.

CPU: {{cpu}}
GPU: {{gpu}}
RAM: {{ram}}

Available Laptops:
${JSON.stringify(laptopData, null, 2)}

Return only the JSON for the suggested laptops.`,
});

const suggestLaptopsFlow = ai.defineFlow(
  {
    name: 'suggestLaptopsFlow',
    inputSchema: SuggestLaptopsInputSchema,
    outputSchema: SuggestLaptopsOutputSchema,
  },
  async (input) => {
    // For this implementation, we will filter locally based on specs.
    // A more advanced implementation could use an LLM with a prompt.
    const suggestions = laptopData.filter(laptop => {
        const cpuSpec = laptop.specs.find(spec => spec.name === 'CPU');
        const gpuSpec = laptop.specs.find(spec => spec.name === 'GPU');
        const ramSpec = laptop.specs.find(spec => spec.name === 'RAM');

        // Simple matching logic, can be improved
        const cpuMatch = cpuSpec && cpuSpec.value.includes(input.cpu.split(' ')[0]);
        const gpuMatch = gpuSpec && gpuSpec.value === input.gpu;
        const ramMatch = ramSpec && parseInt(ramSpec.value) >= parseInt(input.ram);

        return gpuMatch || cpuMatch || ramMatch;
    });

    return { suggestions: suggestions.slice(0, 3) };
  }
);
